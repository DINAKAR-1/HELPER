ðŸ”¥ Kafka Interview Questions & Answers (2-Year Experience, Spring Boot + Java Full Stack)

1. What is Kafka and why do we use it?
ðŸ‘‰ Kafka is a distributed event streaming platform. Instead of services calling each other directly (tight coupling), Kafka lets them talk via events/messages.
We use it for:

Decoupling services (producer doesnâ€™t care who consumes).

Handling high throughput (millions of events/sec).

Scalability & fault tolerance (replication, partitioning).

Event-driven architecture (real-time processing).

2. What are Kafka Topics, Partitions, and Offsets?
ðŸ‘‰ Topic â†’ A category/feed name (like a table in DB).
Partition â†’ A topic is split into multiple partitions for parallelism.
Offset â†’ Each message in a partition gets a unique sequential ID.
Example: If topic orders has 3 partitions, producers can publish to all 3. Consumers track offsets to know whatâ€™s read.

3. How does Kafka ensure fault tolerance?
ðŸ‘‰ Replication: Each partition has a leader and multiple replicas.
If a leader broker dies, a replica is promoted.
Consumers and producers reconnect automatically.
ACKs (acks=0,1,all) ensure durability at different levels.

4. How do you integrate Kafka with Spring Boot?
ðŸ‘‰ Use Spring Kafka dependency. Configure producer/consumer in application.yml.
Use @KafkaListener to consume. Use KafkaTemplate to produce.

@Autowired
private KafkaTemplate<String, String> kafkaTemplate;

public void sendMessage(String msg) {
    kafkaTemplate.send("orders", msg);
}

@KafkaListener(topics = "orders", groupId = "order-group")
public void consume(String message) {
    System.out.println("Consumed: " + message);
}


5. Whatâ€™s the difference between Kafka and traditional message brokers (RabbitMQ/ActiveMQ)?
ðŸ‘‰ Kafka â†’ High throughput, scalable, event streaming. Messages are persisted for a configurable time. Consumers can replay.
RabbitMQ â†’ Better for request-response, low latency, smaller workloads, but not built for heavy streaming.

6. Whatâ€™s a Consumer Group in Kafka?
ðŸ‘‰ A consumer group is a set of consumers that share the work of consuming a topic.
Each partition is consumed by only one consumer in the group.
Scaling consumers = scaling partitions.
Example: Topic has 3 partitions, group has 3 consumers â†’ each consumer gets 1 partition.

7. How do you handle message ordering in Kafka?
ðŸ‘‰ Kafka guarantees ordering within a partition, not across partitions.
To ensure order: send related events to the same partition using a key (e.g., all messages for customerId=123).

8. How do you commit offsets in Kafka?
ðŸ‘‰ Automatic commit â†’ Kafka commits offsets periodically (risk: duplicates).
Manual commit â†’ Developer marks consumed messages (safer for at-least-once).

9. What are delivery semantics in Kafka?
ðŸ‘‰ At most once: Messages may be lost but never redelivered.
At least once (default): No message lost, but duplicates possible.
Exactly once: No loss, no duplicates (idempotent producer + transactional consumer).

10. Can Kafka be used in microservices architecture?
ðŸ‘‰ Yes. Kafka acts as the backbone for event-driven microservices. Producers publish events, consumers react. Enables loose coupling, scalability, resilience.

11. How do you secure Kafka?
ðŸ‘‰ Authentication: SASL (SCRAM, Kerberos).
Authorization: ACLs.
Encryption: TLS for in-transit data.

12. Real-world use cases youâ€™ve seen/implemented with Kafka?
ðŸ‘‰ Logging pipeline (collect logs into Elasticsearch).
Order management (orders â†’ update inventory, billing).
Real-time analytics (Kafka + Spark/Flink).

13. How does Kafka differ from a database?
ðŸ‘‰ Kafka = commit log + streaming. Not for queries/joins like SQL.
Database = storage + query engine. Kafka usually complements DB.

14. Whatâ€™s the role of Zookeeper in Kafka?
ðŸ‘‰ Pre-2.8: Zookeeper managed brokers, partitions, leader election.
Now: Kafka uses KRaft (self-managed) â†’ Zookeeper being phased out.

15. What happens if a consumer is slower than producer?
ðŸ‘‰ Kafka stores data for retention period.
Slow consumer can catch up unless retention expires â†’ then data is lost.

âš¡ Level 2 & 3 Kafka Interview Questions (Deep Dive)

1. Difference between acks=0, acks=1, and acks=all?
ðŸ‘‰ acks=0: Producer doesnâ€™t wait â†’ fastest, but messages may be lost.
acks=1: Waits for leader â†’ possible data loss if leader crashes.
acks=all: Waits for all replicas â†’ safest, slowest.

2. What is an idempotent producer?
ðŸ‘‰ Retries can cause duplicates.
Idempotent producer (enable.idempotence=true) ensures exactly-once delivery per partition using producer ID + sequence numbers.

3. How does consumer rebalancing work?
ðŸ‘‰ In a consumer group, partitions are assigned uniquely.
When a consumer joins/leaves, partitions reassign â†’ temporary stop = rebalance.
Best practice: Cooperative rebalancing (KIP-429) â†’ smoother transitions.

4. Difference between poll() and @KafkaListener in Spring Boot?
ðŸ‘‰ poll(): Low-level API â†’ manual poll loop, offset handling.
@KafkaListener: High-level abstraction â†’ auto handles polling, threading, offsets.
Use poll() for fine control, else @KafkaListener is easier.

5. Whatâ€™s a Dead Letter Queue (DLQ) in Kafka?
ðŸ‘‰ Failed messages (bad JSON, validation error) can be redirected to a DLQ topic. Later reprocessed/debugged.

6. How can you tune Kafka performance?
ðŸ‘‰ Increase partitions (parallelism).
Batching (batch.size) â†’ send in chunks.
linger.ms â†’ wait a bit for batching.
Compression (snappy, lz4) â†’ reduce network overhead.
Async I/O â†’ non-blocking producer.
âš¡ Note: Too many partitions = broker overhead.

7. What is Schema Registry and why do we need it?
ðŸ‘‰ Kafka stores raw bytes â†’ consumers need schema knowledge.
Schema Registry ensures producers & consumers share format (Avro, Protobuf, JSON Schema). Supports schema evolution.

8. Difference between Kafka Streams and a normal consumer?
ðŸ‘‰ Normal Consumer: Reads & processes.
Kafka Streams API: Stream processing library â†’ filtering, joins, windowing, aggregations. Example: join orders + payments â†’ completed_orders.

9. How does Kafka handle data retention?
ðŸ‘‰ Messages kept for retention.ms (time-based) or retention.bytes (size-based).
Consumed messages are not deleted immediately. Useful for replays.

10. How is Kafka monitored in production?
ðŸ‘‰ Metrics: Consumer lag, throughput, broker health.
Tools: Prometheus + Grafana, Confluent Control Center.